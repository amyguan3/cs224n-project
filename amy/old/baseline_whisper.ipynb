{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (24.0)\n",
      "Requirement already satisfied: datasets in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (2.17.1)\n",
      "Requirement already satisfied: transformers in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (4.38.1)\n",
      "Requirement already satisfied: accelerate in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (0.27.2)\n",
      "Requirement already satisfied: soundfile in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (0.12.1)\n",
      "Requirement already satisfied: librosa in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (0.10.1)\n",
      "Requirement already satisfied: evaluate in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: jiwer in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (3.0.3)\n",
      "Requirement already satisfied: tensorboard in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (2.16.2)\n",
      "Requirement already satisfied: gradio in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (4.19.2)\n",
      "Requirement already satisfied: filelock in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: psutil in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=0.14 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (0.58.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: responses<0.19 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from evaluate) (0.13.3)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from jiwer) (8.1.7)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from jiwer) (3.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from tensorboard) (1.62.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (5.2.0)\n",
      "Requirement already satisfied: fastapi in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (0.110.0)\n",
      "Requirement already satisfied: ffmpy in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.10.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (0.10.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (6.1.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (3.9.15)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (2.6.3)\n",
      "Requirement already satisfied: pydub in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (0.2.2)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio) (0.27.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from gradio-client==0.10.1->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio) (4.21.1)\n",
      "Requirement already satisfied: toolz in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: pycparser in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: anyio in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (1.0.4)\n",
      "Requirement already satisfied: idna in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.17.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard) (7.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from pooch>=1.0->librosa) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from scikit-learn>=0.20.0->librosa) (3.3.0)\n",
      "Requirement already satisfied: sympy in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.3.5)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from fastapi->gradio) (0.36.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/amyguan/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade datasets transformers accelerate soundfile librosa evaluate jiwer tensorboard gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import interpreter_login\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, pipeline\n",
    "import evaluate\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/amyguan/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_total = load_dataset(\"mozilla-foundation/common_voice_16_1\", \"en\", split=\"train\", token=True, trust_remote_code=True, streaming=True)\n",
    "# dataset_total.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_total = dataset_total.shuffle(seed=42, buffer_size=10_000)\n",
    "# dataset_total = dataset_total.take(60_000) # approx half of training\n",
    "# dataset_total = dataset_total.filter(lambda example: example['accent'] != '') # doesn't work\n",
    "# dataset_total = dataset_total.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and Init Whisper\n",
    "### note: remember to change the gpu config stuff, change dataset to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7722c58bd34880a836228cbaf48764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b605bb4ac4fc44fe89c18dd6c3358d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb6471cc9cb4f06aaee3c3a637cda1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88b33442ec6458f9465e2192bef9a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from a github repo: https://github.com/vasistalodagala/whisper-finetune/tree/master\n",
    "\n",
    "def is_target_text_in_range(ref):\n",
    "    if ref.strip() == \"ignore time segment in scoring\":\n",
    "        return False\n",
    "    else:\n",
    "        return ref.strip() != \"\"\n",
    "    \n",
    "def get_text(sample):\n",
    "    # can replace with just return sample[\"sentence\"]?\n",
    "    if \"text\" in sample:\n",
    "        return sample[\"text\"]\n",
    "    elif \"sentence\" in sample:\n",
    "        return sample[\"sentence\"]\n",
    "    elif \"normalized_text\" in sample:\n",
    "        return sample[\"normalized_text\"]\n",
    "    elif \"transcript\" in sample:\n",
    "        return sample[\"transcript\"]\n",
    "    elif \"transcription\" in sample:\n",
    "        return sample[\"transcription\"]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Expected transcript column of either 'text', 'sentence', 'normalized_text' or 'transcript'. Got sample of \"\n",
    "            \".join{sample.keys()}. Ensure a text column name is present in the dataset.\"\n",
    "        )\n",
    "    \n",
    "def get_accents(sample):\n",
    "    if \"accent\" in sample:\n",
    "        # can remove the india comma outlier thing\n",
    "        return sample[\"accent\"].split(',')\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Expected transcript column of accent. Ensure an accent column is present in the dataset.\"\n",
    "        )\n",
    "\n",
    "whisper_norm = BasicTextNormalizer()\n",
    "\n",
    "def normalise(batch):\n",
    "    batch[\"norm_text\"] = whisper_norm(get_text(batch))\n",
    "    return batch\n",
    "\n",
    "def data(dataset):\n",
    "    for i, item in enumerate(dataset):\n",
    "        yield {**item[\"audio\"], \"reference\": get_text(item), \"norm_reference\": item[\"norm_text\"], \"accents\": get_accents(item)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device 0 for gpu, device -1 for cpu?\n",
    "whisper_asr = pipeline(\n",
    "    \"automatic-speech-recognition\", model=model, tokenizer=processor.tokenizer, feature_extractor=processor.feature_extractor, device=-1\n",
    ") # \"openai/whisper-small\"\n",
    "\n",
    "whisper_asr.model.config.forced_decoder_ids = (\n",
    "    whisper_asr.tokenizer.get_decoder_prompt_ids(\n",
    "        language=\"english\", task=\"transcribe\"\n",
    "    )\n",
    ")\n",
    "\n",
    "whisper_asr.model.generation_config.forced_decoder_ids = processor.tokenizer.get_decoder_prompt_ids(\n",
    "    language=\"english\", task=\"transcribe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterable dataset\n",
    "dataset_total = load_dataset(\"mozilla-foundation/common_voice_16_1\", \"en\", split=\"train\", token=True, trust_remote_code=True, streaming=True)\n",
    "# dataset_total = load_dataset(\"mozilla-foundation/common_voice_16_1\", \"en\", split=\"train\", token=True, trust_remote_code=True, streaming=True)\n",
    "text_column_name = \"sentence\"\n",
    "\n",
    "dataset_total = dataset_total.shuffle(seed=42, buffer_size=10_000)\n",
    "dataset_total = dataset_total.take(60_000) # approx half of training\n",
    "dataset_total = dataset_total.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "dataset_total = dataset_total.map(normalise) # , num_proc=2\n",
    "dataset_total = dataset_total.filter(is_target_text_in_range, input_columns=[text_column_name]) # , num_proc=2\n",
    "dataset_total = dataset_total.filter(lambda example: example['accent'] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: Unknown,\n",
       "    n_shards: 28\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 1090061it [00:58, 18764.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decode Progress: 240it [10:48,  2.70s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m norm_references \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      7\u001b[0m all_accents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m tqdm(whisper_asr(data(dataset_total), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecode Progress\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m accent \u001b[38;5;129;01min\u001b[39;00m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccents\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]: \u001b[38;5;66;03m# will skip if empty\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# print(out[\"accents\"])\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m accent \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_accents:\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/transformers/pipelines/base.py:1102\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1101\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1102\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/transformers/pipelines/automatic_speech_recognition.py:496\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline._forward\u001b[0;34m(self, model_inputs, return_timestamps, generate_kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    499\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs,\n\u001b[1;32m    501\u001b[0m )\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_timestamps \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq2seq_whisper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/transformers/models/whisper/modeling_whisper.py:1215\u001b[0m, in \u001b[0;36mWhisperEncoder.forward\u001b[0;34m(self, input_features, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1207\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1208\u001b[0m             encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1209\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1212\u001b[0m             output_attentions,\n\u001b[1;32m   1213\u001b[0m         )\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1215\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/transformers/models/whisper/modeling_whisper.py:782\u001b[0m, in \u001b[0;36mWhisperEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    780\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    781\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm(hidden_states)\n\u001b[0;32m--> 782\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    783\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    784\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs224n-final-project/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make these specific per accent?\n",
    "predictions = {}\n",
    "references = {}\n",
    "norm_predictions = {}\n",
    "norm_references = {}\n",
    "\n",
    "all_accents = []\n",
    "\n",
    "for out in tqdm(whisper_asr(data(dataset_total), batch_size=16), desc='Decode Progress'):\n",
    "    for accent in out[\"accents\"][0]: # will skip if empty\n",
    "        # print(out[\"accents\"])\n",
    "        if accent not in all_accents:\n",
    "            all_accents.append(accent)\n",
    "        if accent not in predictions:\n",
    "            predictions[accent] = []\n",
    "        if accent not in references:\n",
    "            references[accent] = []\n",
    "        if accent not in norm_predictions:\n",
    "            norm_predictions[accent] = []\n",
    "        if accent not in norm_references:\n",
    "            norm_references[accent] = []\n",
    "        predictions[accent].append(out[\"text\"])\n",
    "        references[accent].append(out[\"reference\"][0])\n",
    "        norm_predictions[accent].append(whisper_norm(out[\"text\"]))\n",
    "        norm_references[accent].append(out[\"norm_reference\"][0])\n",
    "\n",
    "\"\"\"\n",
    "while True: # ????\n",
    "    try:\n",
    "        # idk about this map fn lowkey\n",
    "        # dataset = dataset_total.map(data, batched=True)\n",
    "        # print('done mapping data')\n",
    "        \n",
    "        for out in tqdm(whisper_asr(data(dataset_total), batch_size=16), desc='Decode Progress'):\n",
    "        # for out in tqdm(whisper_asr(dataset, batch_size=16), desc='Decode Progress'):\n",
    "            # predictions.append(out[\"text\"])\n",
    "            # references.append(out[\"reference\"][0])\n",
    "            \n",
    "            print('test!')\n",
    "            # for accent in out[\"accents\"]: # will skip if empty\n",
    "            #     print(out[\"accents\"])\n",
    "            #     if accent not in all_accents:\n",
    "            #         all_accents.append(accent)\n",
    "            #     if accent not in predictions:\n",
    "            #         predictions[accent] = []\n",
    "            #     if accent not in references:\n",
    "            #         references[accent] = []\n",
    "            #     if accent not in norm_predictions:\n",
    "            #         norm_predictions[accent] = []\n",
    "            #     if accent not in norm_references:\n",
    "            #         norm_references[accent] = []\n",
    "            #     predictions[accent].append(out[\"text\"])\n",
    "            #     references[accent].append(out[\"reference\"][0])\n",
    "            #     norm_predictions[accent].append(whisper_norm(out[\"text\"]))\n",
    "            #     norm_references[accent].append(out[\"norm_reference\"][0])\n",
    "\n",
    "        # dataset_total.skip(i * 1028)\n",
    "        # dataset_it = dataset_total.take(1028)\n",
    "        # print('iter done')\n",
    "        # dataset = Dataset.from_generator(lambda: (yield from dataset_it), features=dataset_it.features)\n",
    "        # for out in tqdm(whisper_asr(data(dataset), batch_size=16), desc='Decode Progress'):\n",
    "        #     # predictions.append(out[\"text\"])\n",
    "        #     # references.append(out[\"reference\"][0])\n",
    "            \n",
    "        #     for accent in out[\"accents\"]: # will skip if empty\n",
    "        #         print(out[\"accents\"])\n",
    "        #         if accent not in all_accents:\n",
    "        #             all_accents.append(accent)\n",
    "        #         if accent not in predictions:\n",
    "        #             predictions[accent] = []\n",
    "        #         if accent not in references:\n",
    "        #             references[accent] = []\n",
    "        #         if accent not in norm_predictions:\n",
    "        #             norm_predictions[accent] = []\n",
    "        #         if accent not in norm_references:\n",
    "        #             norm_references[accent] = []\n",
    "        #         predictions[accent].append(out[\"text\"])\n",
    "        #         references[accent].append(out[\"reference\"][0])\n",
    "        #         norm_predictions[accent].append(whisper_norm(out[\"text\"]))\n",
    "        #         norm_references[accent].append(out[\"norm_reference\"][0])\n",
    "    except:\n",
    "        print(\"done going through whole dataset (???)\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(f\"mkdir -p predictions/\")\n",
    "import os\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "for accent in all_accents:\n",
    "    wer = wer_metric.compute(references=references[accent], predictions=predictions[accent])\n",
    "    wer = round(100 * wer, 2)\n",
    "    cer = cer_metric.compute(references=references[accent], predictions=predictions[accent])\n",
    "    cer = round(100 * cer, 2)\n",
    "    norm_wer = wer_metric.compute(references=norm_references[accent], predictions=norm_predictions[accent])\n",
    "    norm_wer = round(100 * norm_wer, 2)\n",
    "    norm_cer = cer_metric.compute(references=norm_references[accent], predictions=norm_predictions[accent])\n",
    "    norm_cer = round(100 * norm_cer, 2)\n",
    "\n",
    "    # print(\"\\nACCENT: \", accent)\n",
    "    # print(\"\\nWER : \", wer)\n",
    "    # print(\"CER : \", cer)\n",
    "    # print(\"\\nNORMALIZED WER : \", norm_wer)\n",
    "    # print(\"NORMALIZED CER : \", norm_cer)\n",
    "\n",
    "    acc_name = whisper_norm(accent).strip().replace(' ', '_')\n",
    "    if acc_name == 'pakistan' or acc_name == 'sri_lanka':\n",
    "        continue\n",
    "\n",
    "    metrics[acc_name] = {'wer': wer, 'cer': cer, 'norm_wer': norm_wer, 'norm_cer': norm_cer}\n",
    "\n",
    "    os.system(f\"mkdir -p predictions\")\n",
    "    # os.system(f\"mkdir -p predictions/{acc_name}\")\n",
    "    op_file = f\"predictions/{acc_name}.txt\" # ??\n",
    "    result_file = open(op_file, 'w') # a? or w?\n",
    "    result_file.write('ACCENT: ' + str(accent) + '\\n')\n",
    "    result_file.write('\\nWER: ' + str(wer) + '\\n')\n",
    "    result_file.write('CER: ' + str(cer) + '\\n')\n",
    "    result_file.write('\\nNORMALIZED WER: ' + str(norm_wer) + '\\n')\n",
    "    result_file.write('NORMALIZED CER: ' + str(norm_cer) + '\\n\\n\\n')\n",
    "\n",
    "    for ref, hyp in zip(references[accent], predictions[accent]):\n",
    "        result_file.write('REF: ' + ref + '\\n')\n",
    "        result_file.write('HYP: ' + hyp + '\\n')\n",
    "        result_file.write(\"------------------------------------------------------\" + '\\n')\n",
    "    result_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
